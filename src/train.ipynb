{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "Updated with NOISE_STD, VGG_WEIGHT, and library imports. Checks for GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:43.166675Z",
     "iopub.status.busy": "2025-12-06T12:05:43.166344Z",
     "iopub.status.idle": "2025-12-06T12:05:43.191854Z",
     "shell.execute_reply": "2025-12-06T12:05:43.191104Z",
     "shell.execute_reply.started": "2025-12-06T12:05:43.166645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# FIXED: Updated AMP imports\n",
    "from torch.amp import autocast, GradScaler \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.auto import tqdm  # FIXED: Progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100\n",
    "PHYSICS_WEIGHT = 0.1\n",
    "VGG_WEIGHT = 0.1\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Device: {device}\")\n",
    "\n",
    "# Dataset Discovery\n",
    "search_path = \"/kaggle/input/**/*.pt\"\n",
    "pt_files = glob.glob(search_path, recursive=True)\n",
    "if not pt_files:\n",
    "    raise FileNotFoundError(\"âŒ Dataset not found!\")\n",
    "DATA_FILE = pt_files[0]\n",
    "DATA_DIR = os.path.dirname(DATA_FILE)\n",
    "STATS_FILE = os.path.join(DATA_DIR, \"normalization_stats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class \n",
    "Added ```noise_std``` parameter for Sim-to-Real gap augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:53.919478Z",
     "iopub.status.busy": "2025-12-06T12:05:53.918948Z",
     "iopub.status.idle": "2025-12-06T12:05:53.927893Z",
     "shell.execute_reply": "2025-12-06T12:05:53.927269Z",
     "shell.execute_reply.started": "2025-12-06T12:05:53.919455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FluidLoader(Dataset):\n",
    "    def __init__(self, pt_file, stats_file, target_res=256):\n",
    "        print(f\"â³ Loading data map...\")\n",
    "        try:\n",
    "            data = torch.load(pt_file, map_location='cpu', mmap=True)\n",
    "        except:\n",
    "            data = torch.load(pt_file, map_location='cpu')\n",
    "            \n",
    "        self.inputs = data['inputs']\n",
    "        self.targets = data['targets']\n",
    "        self.target_res = target_res\n",
    "        \n",
    "        # FIXED: Check resolution once at startup\n",
    "        # We check the first sample to determine if upscaling is needed\n",
    "        sample_h = self.inputs.shape[-1]\n",
    "        self.needs_upscale = (sample_h != target_res)\n",
    "        \n",
    "        # Load K\n",
    "        if 'K' in data:\n",
    "            self.K = float(data['K'])\n",
    "        elif os.path.exists(stats_file):\n",
    "            with open(stats_file, 'r') as f:\n",
    "                stats = json.load(f)\n",
    "            self.K = float(stats['scaling_factor'])\n",
    "        else:\n",
    "            self.K = 1.0\n",
    "            \n",
    "        print(f\"âœ… Loaded {len(self.inputs)} samples. Upscaling: {self.needs_upscale}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # FIXED: Removed .clone() (F.interpolate creates a new tensor anyway)\n",
    "        lr = self.inputs[idx] \n",
    "        hr = self.targets[idx]\n",
    "        \n",
    "        # FIXED: Use pre-calculated flag instead of checking shape every time\n",
    "        if self.needs_upscale:\n",
    "            lr = F.interpolate(\n",
    "                lr.unsqueeze(0), \n",
    "                size=(self.target_res, self.target_res), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            ).squeeze(0)\n",
    "            \n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture (ResUNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:56.986497Z",
     "iopub.status.busy": "2025-12-06T12:05:56.986214Z",
     "iopub.status.idle": "2025-12-06T12:05:57.001710Z",
     "shell.execute_reply": "2025-12-06T12:05:57.000949Z",
     "shell.execute_reply.started": "2025-12-06T12:05:56.986475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, out_channels=2, features=[64, 128, 256, 512]):\n",
    "        super(ResUNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        input_feat = features[0]\n",
    "        for feature in features:\n",
    "            self.encoder.append(ResidualBlock(input_feat, feature))\n",
    "            input_feat = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualBlock(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconvs = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        features = features[::-1]\n",
    "        for feature in features:\n",
    "            self.upconvs.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.decoder.append(ResidualBlock(feature * 2, feature))\n",
    "\n",
    "        # Output\n",
    "        self.final_conv = nn.Conv2d(features[-1], out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        out = self.input_conv(x)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            out = layer(out)\n",
    "            skip_connections.append(out)\n",
    "            out = self.pool(out)\n",
    "            \n",
    "        out = self.bottleneck(out)\n",
    "        skip_connections = skip_connections[::-1] \n",
    "        \n",
    "        for idx in range(len(self.decoder)):\n",
    "            out = self.upconvs[idx](out)\n",
    "            skip = skip_connections[idx]\n",
    "            if out.shape != skip.shape:\n",
    "                out = F.interpolate(out, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "            concat_skip = torch.cat((skip, out), dim=1)\n",
    "            out = self.decoder[idx](concat_skip)\n",
    "            \n",
    "        out = self.final_conv(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions ( VGG, Physics Informed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:01.086884Z",
     "iopub.status.busy": "2025-12-06T12:06:01.086092Z",
     "iopub.status.idle": "2025-12-06T12:06:01.093853Z",
     "shell.execute_reply": "2025-12-06T12:06:01.093110Z",
     "shell.execute_reply.started": "2025-12-06T12:06:01.086854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg.features.children())[:35]).eval()\n",
    "        \n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # FIXED: ImageNet Normalization constants as buffers\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
    "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # 1. Expand 2 channel -> 3 channel (Append Zero channel)\n",
    "        # Using pad is more efficient than creating zeros and catting\n",
    "        # Pad format: (left, right, top, bottom, front, back) for last 3 dims? \n",
    "        # F.pad for 4D input (B, C, H, W) pads starting from last dim.\n",
    "        # We want to pad Channel dim. F.pad tuple is (W_l, W_r, H_t, H_b, C_f, C_b)?? No.\n",
    "        # Simple concat is safer for clarity, but lets optimize allocation.\n",
    "        \n",
    "        b, c, h, w = input.shape\n",
    "        # Create zero channel ONCE per batch if size constant? \n",
    "        # Just stick to cat for safety but ensure device match.\n",
    "        zeros = torch.zeros(b, 1, h, w, device=input.device, dtype=input.dtype)\n",
    "        \n",
    "        input_3c = torch.cat([input, zeros], dim=1)\n",
    "        target_3c = torch.cat([target, zeros], dim=1)\n",
    "        \n",
    "        # 2. FIXED: Normalize to ImageNet stats\n",
    "        # VGG expects [0, 1] usually, but our data is normalized by K.\n",
    "        # We assume input is roughly in reasonable range, but centering helps.\n",
    "        input_norm = (input_3c - self.mean) / self.std\n",
    "        target_norm = (target_3c - self.mean) / self.std\n",
    "        \n",
    "        input_features = self.feature_extractor(input_norm)\n",
    "        target_features = self.feature_extractor(target_norm)\n",
    "        return F.mse_loss(input_features, target_features)\n",
    "\n",
    "class DivergenceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DivergenceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, scaling_factor):\n",
    "        u = output[:, 0, :, :] * scaling_factor\n",
    "        v = output[:, 1, :, :] * scaling_factor\n",
    "        du_dx = u[:, :, 1:] - u[:, :, :-1]\n",
    "        dv_dy = v[:, 1:, :] - v[:, :-1, :]\n",
    "        return torch.mean((du_dx[:, :-1, :] + dv_dy[:, :, :-1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:03.829416Z",
     "iopub.status.busy": "2025-12-06T12:06:03.829140Z",
     "iopub.status.idle": "2025-12-06T12:06:03.834680Z",
     "shell.execute_reply": "2025-12-06T12:06:03.833957Z",
     "shell.execute_reply.started": "2025-12-06T12:06:03.829397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(use_physics=False, mse_weight=1.0, vgg_weight=0.1, physics_weight=0.1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        use_physics (bool): Whether to enable divergence loss.\n",
    "        mse_weight (float): Weight for Pixel Loss (MSE).\n",
    "        vgg_weight (float): Weight for Perceptual Loss (VGG).\n",
    "        physics_weight (float): Weight for Divergence Loss (if use_physics=True).\n",
    "    \"\"\"\n",
    "    # 1. Data\n",
    "    dataset = FluidLoader(DATA_FILE, STATS_FILE)\n",
    "    train_sz = int(0.8 * len(dataset))\n",
    "    val_sz = len(dataset) - train_sz\n",
    "    train_ds, val_ds = random_split(dataset, [train_sz, val_sz], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # 2. Setup\n",
    "    model = ResUNet(in_channels=6, out_channels=2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    scaler = GradScaler('cuda') \n",
    "    \n",
    "    # Loss Functions\n",
    "    mse_fn = nn.MSELoss()\n",
    "    vgg_fn = VGGLoss().to(device)\n",
    "    div_fn = DivergenceLoss().to(device)\n",
    "    K = dataset.K\n",
    "    \n",
    "    mode_name = \"PINN\" if use_physics else \"Baseline\"\n",
    "    print(f\"\\nðŸš€ Starting {mode_name} Training...\")\n",
    "    print(f\"   > Weights: MSE={mse_weight} | VGG={vgg_weight} | Physics={physics_weight if use_physics else 0.0}\")\n",
    "    \n",
    "    hist = {'train': [], 'val': [], 'lr': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 7\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "        \n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True) \n",
    "            \n",
    "            with autocast('cuda'): \n",
    "                pred = model(x)\n",
    "                \n",
    "                # --- Weighted Loss Calculation ---\n",
    "                loss = 0.0\n",
    "                \n",
    "                # 1. MSE Loss (Pixel Accuracy)\n",
    "                if mse_weight > 0:\n",
    "                    loss += mse_weight * mse_fn(pred, y)\n",
    "                \n",
    "                # 2. VGG Loss (Texture/Sharpness)\n",
    "                if vgg_weight > 0:\n",
    "                    loss += vgg_weight * vgg_fn(pred, y)\n",
    "                \n",
    "                # 3. Physics Loss (Divergence/Mass)\n",
    "                if use_physics and physics_weight > 0:\n",
    "                    loss += physics_weight * div_fn(pred, K)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                with autocast('cuda'):\n",
    "                    pred = model(x)\n",
    "                    # Track MSE for early stopping (standard metric)\n",
    "                    val_loss += mse_fn(pred, y).item()\n",
    "        \n",
    "        avg_train = train_loss / len(train_loader)\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        \n",
    "        # Step Scheduler\n",
    "        scheduler.step(avg_val)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        hist['train'].append(avg_train)\n",
    "        hist['val'].append(avg_val)\n",
    "        hist['lr'].append(current_lr)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Train: {avg_train:.6f} | Val: {avg_val:.6f} | LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # Checkpointing\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val,\n",
    "        }\n",
    "        \n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            counter = 0\n",
    "            torch.save(checkpoint, f\"{OUTPUT_DIR}/{mode_name}_best.pth\")\n",
    "            print(\"  --> New Best Model Saved!\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"ðŸ›‘ Early Stopping triggered.\")\n",
    "                break\n",
    "                \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist['train'], label='Train')\n",
    "    plt.plot(hist['val'], label='Val')\n",
    "    plt.title(f'{mode_name} Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist['lr'], color='orange')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.savefig(f\"{OUTPUT_DIR}/{mode_name}_history.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    best_checkpoint = torch.load(f\"{OUTPUT_DIR}/{mode_name}_best.pth\")\n",
    "    model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute\n",
    "Run this cell to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:12.555688Z",
     "iopub.status.busy": "2025-12-06T12:06:12.555079Z",
     "iopub.status.idle": "2025-12-06T14:21:52.384643Z",
     "shell.execute_reply": "2025-12-06T14:21:52.383999Z",
     "shell.execute_reply.started": "2025-12-06T12:06:12.555667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration 1: Standard (Balanced)\n",
    "model, ds = train(\n",
    "    use_physics=True, \n",
    "    mse_weight=1.0, \n",
    "    vgg_weight=0.1, \n",
    "    physics_weight=0.1\n",
    ")\n",
    "\n",
    "# Configuration 2: High Sharpness (Native Data Fine-Tuning)\n",
    "# model, ds = train(\n",
    "#     use_physics=True, \n",
    "#     mse_weight=0.05,   # Low MSE to allow spatial shift\n",
    "#     vgg_weight=1.0,    # High VGG for texture\n",
    "#     physics_weight=0.2 # Physics to keep it valid\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8927398,
     "sourceId": 14013478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

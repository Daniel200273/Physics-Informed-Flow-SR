{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "Updated with NOISE_STD, VGG_WEIGHT, and library imports. Checks for GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:43.166675Z",
     "iopub.status.busy": "2025-12-06T12:05:43.166344Z",
     "iopub.status.idle": "2025-12-06T12:05:43.191854Z",
     "shell.execute_reply": "2025-12-06T12:05:43.191104Z",
     "shell.execute_reply.started": "2025-12-06T12:05:43.166645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# FIXED: Updated AMP imports\n",
    "from torch.amp import autocast, GradScaler \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.auto import tqdm  # FIXED: Progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 50\n",
    "PHYSICS_WEIGHT = 0.3  # Increased for stronger divergence-free constraint\n",
    "SPECTRAL_WEIGHT = 0.3  # Increased to compensate for removed vorticity\n",
    "VORTICITY_WEIGHT = 0.2  # Vorticity matching weight\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "# Dataset Discovery\n",
    "search_path = \"/kaggle/input/**/*.pt\"\n",
    "pt_files = glob.glob(search_path, recursive=True)\n",
    "if not pt_files:\n",
    "    raise FileNotFoundError(\"‚ùå Dataset not found!\")\n",
    "DATA_FILE = pt_files[0]\n",
    "DATA_DIR = os.path.dirname(DATA_FILE)\n",
    "STATS_FILE = os.path.join(DATA_DIR, \"normalization_stats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class \n",
    "Added ```noise_std``` parameter for Sim-to-Real gap augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:53.919478Z",
     "iopub.status.busy": "2025-12-06T12:05:53.918948Z",
     "iopub.status.idle": "2025-12-06T12:05:53.927893Z",
     "shell.execute_reply": "2025-12-06T12:05:53.927269Z",
     "shell.execute_reply.started": "2025-12-06T12:05:53.919455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FluidLoader(Dataset):\n",
    "    def __init__(self, pt_file, stats_file, target_res=256):\n",
    "        print(f\"‚è≥ Loading data map...\")\n",
    "        try:\n",
    "            data = torch.load(pt_file, map_location='cpu', mmap=True)\n",
    "        except:\n",
    "            data = torch.load(pt_file, map_location='cpu')\n",
    "            \n",
    "        self.inputs = data['inputs']\n",
    "        self.targets = data['targets']\n",
    "        self.target_res = target_res\n",
    "        \n",
    "        # FIXED: Check resolution once at startup\n",
    "        # We check the first sample to determine if upscaling is needed\n",
    "        sample_h = self.inputs.shape[-1]\n",
    "        self.needs_upscale = (sample_h != target_res)\n",
    "        \n",
    "        # Load K\n",
    "        if 'K' in data:\n",
    "            self.K = float(data['K'])\n",
    "        elif os.path.exists(stats_file):\n",
    "            with open(stats_file, 'r') as f:\n",
    "                stats = json.load(f)\n",
    "            self.K = float(stats['scaling_factor'])\n",
    "        else:\n",
    "            self.K = 1.0\n",
    "            \n",
    "        print(f\"‚úÖ Loaded {len(self.inputs)} samples. Upscaling: {self.needs_upscale}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # FIXED: Removed .clone() (F.interpolate creates a new tensor anyway)\n",
    "        lr = self.inputs[idx] \n",
    "        hr = self.targets[idx]\n",
    "        \n",
    "        # FIXED: Use pre-calculated flag instead of checking shape every time\n",
    "        if self.needs_upscale:\n",
    "            lr = F.interpolate(\n",
    "                lr.unsqueeze(0), \n",
    "                size=(self.target_res, self.target_res), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            ).squeeze(0)\n",
    "            \n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture (ResUNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:05:56.986497Z",
     "iopub.status.busy": "2025-12-06T12:05:56.986214Z",
     "iopub.status.idle": "2025-12-06T12:05:57.001710Z",
     "shell.execute_reply": "2025-12-06T12:05:57.000949Z",
     "shell.execute_reply.started": "2025-12-06T12:05:56.986475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, out_channels=2, features=[64, 128, 256, 512]):\n",
    "        super(ResUNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        input_feat = features[0]\n",
    "        for feature in features:\n",
    "            self.encoder.append(ResidualBlock(input_feat, feature))\n",
    "            input_feat = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualBlock(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconvs = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        features = features[::-1]\n",
    "        for feature in features:\n",
    "            self.upconvs.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.decoder.append(ResidualBlock(feature * 2, feature))\n",
    "\n",
    "        # Output\n",
    "        self.final_conv = nn.Conv2d(features[-1], out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        out = self.input_conv(x)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            out = layer(out)\n",
    "            skip_connections.append(out)\n",
    "            out = self.pool(out)\n",
    "            \n",
    "        out = self.bottleneck(out)\n",
    "        skip_connections = skip_connections[::-1] \n",
    "        \n",
    "        for idx in range(len(self.decoder)):\n",
    "            out = self.upconvs[idx](out)\n",
    "            skip = skip_connections[idx]\n",
    "            if out.shape != skip.shape:\n",
    "                out = F.interpolate(out, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "            concat_skip = torch.cat((skip, out), dim=1)\n",
    "            out = self.decoder[idx](concat_skip)\n",
    "            \n",
    "        out = self.final_conv(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions ( VGG, Physics Informed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:01.086884Z",
     "iopub.status.busy": "2025-12-06T12:06:01.086092Z",
     "iopub.status.idle": "2025-12-06T12:06:01.093853Z",
     "shell.execute_reply": "2025-12-06T12:06:01.093110Z",
     "shell.execute_reply.started": "2025-12-06T12:06:01.086854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Spectral and Vorticity losses replace VGG for velocity fields\n",
    "class SpectralLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectralLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # Compute FFT magnitude for each channel and match spectra\n",
    "        # Assumes inputs are (B, 2, H, W)\n",
    "        pred_fft = torch.fft.rfft2(pred, norm='ortho')\n",
    "        targ_fft = torch.fft.rfft2(target, norm='ortho')\n",
    "        pred_mag = torch.abs(pred_fft)\n",
    "        targ_mag = torch.abs(targ_fft)\n",
    "        return F.l1_loss(pred_mag, targ_mag)\n",
    "\n",
    "def compute_vorticity(field):\n",
    "    # field: (B, 2, H, W) with channels (u, v)\n",
    "    u = field[:, 0]\n",
    "    v = field[:, 1]\n",
    "    # Centered differences with padding\n",
    "    u_pad = F.pad(u, (1,1,1,1), mode='replicate')\n",
    "    v_pad = F.pad(v, (1,1,1,1), mode='replicate')\n",
    "    du_dy = (u_pad[:, 2:, 1:-1] - u_pad[:, :-2, 1:-1]) * 0.5\n",
    "    dv_dx = (v_pad[:, 1:-1, 2:] - v_pad[:, 1:-1, :-2]) * 0.5\n",
    "    return dv_dx - du_dy\n",
    "\n",
    "class VorticityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VorticityLoss, self).__init__()\n",
    "        self.spectral = SpectralLoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        w_pred = compute_vorticity(pred)\n",
    "        w_targ = compute_vorticity(target)\n",
    "        vort_l2 = F.mse_loss(w_pred, w_targ)\n",
    "        # Optional: spectral match on vorticity magnitude\n",
    "        w_pred_fft = torch.fft.rfft2(w_pred, norm='ortho')\n",
    "        w_targ_fft = torch.fft.rfft2(w_targ, norm='ortho')\n",
    "        spec_l1 = F.l1_loss(torch.abs(w_pred_fft), torch.abs(w_targ_fft))\n",
    "        return vort_l2 + 0.5 * spec_l1\n",
    "\n",
    "class DivergenceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DivergenceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, scaling_factor, mask=None):\n",
    "        # output: (B, 2, H, W); mask: (B, 1, H, W) where 1 means active fluid\n",
    "        u = output[:, 0] * scaling_factor\n",
    "        v = output[:, 1] * scaling_factor\n",
    "        # Centered differences with replicate padding to limit boundary artifacts\n",
    "        u_pad = F.pad(u, (1,1,1,1), mode='replicate')\n",
    "        v_pad = F.pad(v, (1,1,1,1), mode='replicate')\n",
    "        du_dx = (u_pad[:, 1:-1, 2:] - u_pad[:, 1:-1, :-2]) * 0.5\n",
    "        dv_dy = (v_pad[:, 2:, 1:-1] - v_pad[:, :-2, 1:-1]) * 0.5\n",
    "        div = du_dx + dv_dy\n",
    "        if mask is not None:\n",
    "            div = div * mask.squeeze(1)\n",
    "        return torch.mean(div**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, target, K=1.0):\n",
    "    \"\"\"\n",
    "    Compute physics-aware metrics for evaluation.\n",
    "    \n",
    "    Args:\n",
    "        pred: (B, 2, H, W) predicted velocity field\n",
    "        target: (B, 2, H, W) ground truth velocity field\n",
    "        K: scaling factor\n",
    "    \n",
    "    Returns:\n",
    "        dict of metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. MSE\n",
    "    metrics['mse'] = F.mse_loss(pred, target).item()\n",
    "    \n",
    "    # 2. Divergence error\n",
    "    u_pred = pred[:, 0] * K\n",
    "    v_pred = pred[:, 1] * K\n",
    "    u_targ = target[:, 0] * K\n",
    "    v_targ = target[:, 1] * K\n",
    "    \n",
    "    # Centered differences\n",
    "    u_pred_pad = F.pad(u_pred, (1,1,1,1), mode='replicate')\n",
    "    v_pred_pad = F.pad(v_pred, (1,1,1,1), mode='replicate')\n",
    "    u_targ_pad = F.pad(u_targ, (1,1,1,1), mode='replicate')\n",
    "    v_targ_pad = F.pad(v_targ, (1,1,1,1), mode='replicate')\n",
    "    \n",
    "    div_pred = (u_pred_pad[:, 1:-1, 2:] - u_pred_pad[:, 1:-1, :-2]) * 0.5 + \\\n",
    "               (v_pred_pad[:, 2:, 1:-1] - v_pred_pad[:, :-2, 1:-1]) * 0.5\n",
    "    div_targ = (u_targ_pad[:, 1:-1, 2:] - u_targ_pad[:, 1:-1, :-2]) * 0.5 + \\\n",
    "               (v_targ_pad[:, 2:, 1:-1] - v_targ_pad[:, :-2, 1:-1]) * 0.5\n",
    "    \n",
    "    metrics['div_l2_pred'] = torch.sqrt(torch.mean(div_pred**2)).item()\n",
    "    metrics['div_l2_targ'] = torch.sqrt(torch.mean(div_targ**2)).item()\n",
    "    metrics['div_max_pred'] = torch.max(torch.abs(div_pred)).item()\n",
    "    \n",
    "    # 3. Vorticity error\n",
    "    w_pred = compute_vorticity(pred * K)\n",
    "    w_targ = compute_vorticity(target * K)\n",
    "    metrics['vort_mse'] = F.mse_loss(w_pred, w_targ).item()\n",
    "    \n",
    "    # 4. Energy spectrum correlation (simplified)\n",
    "    pred_fft = torch.fft.rfft2(pred, norm='ortho')\n",
    "    targ_fft = torch.fft.rfft2(target, norm='ortho')\n",
    "    pred_energy = torch.abs(pred_fft).pow(2).mean().item()\n",
    "    targ_energy = torch.abs(targ_fft).pow(2).mean().item()\n",
    "    metrics['energy_pred'] = pred_energy\n",
    "    metrics['energy_targ'] = targ_energy\n",
    "    metrics['energy_ratio'] = pred_energy / (targ_energy + 1e-8)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def visualize_field_comparison(lr, pred, target, idx=0, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize LR input, SR prediction, and HR ground truth with vorticity.\n",
    "    \n",
    "    Args:\n",
    "        lr: (B, 6, H, W) LR input (first 2 channels are velocity)\n",
    "        pred: (B, 2, H, W) predicted HR velocity\n",
    "        target: (B, 2, H, W) ground truth HR velocity\n",
    "        idx: batch index to visualize\n",
    "        save_path: optional path to save figure\n",
    "    \"\"\"\n",
    "    # Extract velocity magnitude\n",
    "    lr_vel = lr[idx, :2].cpu()\n",
    "    pred_vel = pred[idx].cpu()\n",
    "    targ_vel = target[idx].cpu()\n",
    "    \n",
    "    lr_mag = torch.sqrt(lr_vel[0]**2 + lr_vel[1]**2).numpy()\n",
    "    pred_mag = torch.sqrt(pred_vel[0]**2 + pred_vel[1]**2).numpy()\n",
    "    targ_mag = torch.sqrt(targ_vel[0]**2 + targ_vel[1]**2).numpy()\n",
    "    \n",
    "    # Compute vorticity\n",
    "    lr_vort = compute_vorticity(lr_vel.unsqueeze(0)).squeeze(0).numpy()\n",
    "    pred_vort = compute_vorticity(pred_vel.unsqueeze(0)).squeeze(0).numpy()\n",
    "    targ_vort = compute_vorticity(targ_vel.unsqueeze(0)).squeeze(0).numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Row 1: Velocity magnitude\n",
    "    im0 = axes[0,0].imshow(lr_mag, cmap='viridis')\n",
    "    axes[0,0].set_title('LR Input (Velocity Mag)')\n",
    "    plt.colorbar(im0, ax=axes[0,0])\n",
    "    \n",
    "    im1 = axes[0,1].imshow(pred_mag, cmap='viridis')\n",
    "    axes[0,1].set_title('SR Prediction (Velocity Mag)')\n",
    "    plt.colorbar(im1, ax=axes[0,1])\n",
    "    \n",
    "    im2 = axes[0,2].imshow(targ_mag, cmap='viridis')\n",
    "    axes[0,2].set_title('HR Target (Velocity Mag)')\n",
    "    plt.colorbar(im2, ax=axes[0,2])\n",
    "    \n",
    "    # Row 2: Vorticity\n",
    "    vmin = min(lr_vort.min(), pred_vort.min(), targ_vort.min())\n",
    "    vmax = max(lr_vort.max(), pred_vort.max(), targ_vort.max())\n",
    "    \n",
    "    im3 = axes[1,0].imshow(lr_vort, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "    axes[1,0].set_title('LR Vorticity')\n",
    "    plt.colorbar(im3, ax=axes[1,0])\n",
    "    \n",
    "    im4 = axes[1,1].imshow(pred_vort, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "    axes[1,1].set_title('SR Vorticity')\n",
    "    plt.colorbar(im4, ax=axes[1,1])\n",
    "    \n",
    "    im5 = axes[1,2].imshow(targ_vort, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
    "    axes[1,2].set_title('HR Vorticity')\n",
    "    plt.colorbar(im5, ax=axes[1,2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Compute physics-aware metrics: divergence, vorticity spectra, and energy spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:03.829416Z",
     "iopub.status.busy": "2025-12-06T12:06:03.829140Z",
     "iopub.status.idle": "2025-12-06T12:06:03.834680Z",
     "shell.execute_reply": "2025-12-06T12:06:03.833957Z",
     "shell.execute_reply.started": "2025-12-06T12:06:03.829397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(use_physics=False):\n",
    "    # 1. Data\n",
    "    dataset = FluidLoader(DATA_FILE, STATS_FILE)\n",
    "    train_sz = int(0.8 * len(dataset))\n",
    "    val_sz = len(dataset) - train_sz\n",
    "    train_ds, val_ds = random_split(dataset, [train_sz, val_sz], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Num_workers=2 is usually safe on Kaggle\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # 2. Setup\n",
    "    model = ResUNet(in_channels=6, out_channels=2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # FIXED: Added Scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    # FIXED: Updated Scaler init\n",
    "    scaler = GradScaler('cuda') \n",
    "    \n",
    "    mse_fn = nn.MSELoss()\n",
    "    spec_fn = SpectralLoss().to(device)\n",
    "    vort_fn = VorticityLoss().to(device)\n",
    "    div_fn = DivergenceLoss().to(device)\n",
    "    K = dataset.K\n",
    "    \n",
    "    mode_name = \"PINN\" if use_physics else \"Baseline\"\n",
    "    print(f\"\\nüöÄ Starting {mode_name} Training...\")\n",
    "    \n",
    "    hist = {'train': [], 'val': [], 'lr': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 7\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # FIXED: TQDM Progress Bar\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "        \n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True) # set_to_none is slightly faster\n",
    "            \n",
    "            with autocast('cuda'): \n",
    "                pred = model(x)\n",
    "                \n",
    "                # Losses\n",
    "                loss = mse_fn(pred, y)\n",
    "                loss += SPECTRAL_WEIGHT * spec_fn(pred, y)\n",
    "                loss += VORTICITY_WEIGHT * vort_fn(pred, y)\n",
    "                \n",
    "                if use_physics:\n",
    "                    # Physics: Divergence-free with optional mask (None for now)\n",
    "                    loss += PHYSICS_WEIGHT * div_fn(pred, K, mask=None)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # FIXED: Gradient Clipping (Unscale before clipping)\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics_accum = {'div_l2_pred': 0, 'vort_mse': 0, 'energy_ratio': 0}\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                with autocast('cuda'):\n",
    "                    pred = model(x)\n",
    "                    val_loss += mse_fn(pred, y).item()\n",
    "                    # Compute physics metrics\n",
    "                    batch_metrics = compute_metrics(pred, y, K)\n",
    "                    for k in val_metrics_accum:\n",
    "                        val_metrics_accum[k] += batch_metrics[k]\n",
    "        \n",
    "        avg_train = train_loss / len(train_loader)\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        for k in val_metrics_accum:\n",
    "            val_metrics_accum[k] /= len(val_loader)\n",
    "        \n",
    "        # Step Scheduler\n",
    "        scheduler.step(avg_val)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        hist['train'].append(avg_train)\n",
    "        hist['val'].append(avg_val)\n",
    "        hist['lr'].append(current_lr)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Train: {avg_train:.6f} | Val: {avg_val:.6f} | LR: {current_lr:.2e}\")\n",
    "        print(f\"  Metrics: Div={val_metrics_accum['div_l2_pred']:.4f} | Vort={val_metrics_accum['vort_mse']:.4f} | Energy={val_metrics_accum['energy_ratio']:.3f}\")\n",
    "        \n",
    "        # FIXED: Better Checkpointing\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val,\n",
    "        }\n",
    "        \n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            counter = 0\n",
    "            torch.save(checkpoint, f\"{OUTPUT_DIR}/{mode_name}_best.pth\")\n",
    "            print(\"  --> New Best Model Saved!\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"üõë Early Stopping triggered.\")\n",
    "                break\n",
    "                \n",
    "    # FIXED: Plotting improvements\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist['train'], label='Train')\n",
    "    plt.plot(hist['val'], label='Val')\n",
    "    plt.title(f'{mode_name} Loss')\n",
    "    plt.yscale('log') # Log scale is often better for loss\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist['lr'], color='orange')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.savefig(f\"{OUTPUT_DIR}/{mode_name}_history.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Reload best model for return\n",
    "    best_checkpoint = torch.load(f\"{OUTPUT_DIR}/{mode_name}_best.pth\")\n",
    "    model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute\n",
    "Run this cell to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T12:06:12.555688Z",
     "iopub.status.busy": "2025-12-06T12:06:12.555079Z",
     "iopub.status.idle": "2025-12-06T14:21:52.384643Z",
     "shell.execute_reply": "2025-12-06T14:21:52.383999Z",
     "shell.execute_reply.started": "2025-12-06T12:06:12.555667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Run Baseline Training ---\n",
    "# 1. Train the model (Physics is OFF for baseline)\n",
    "#model, dataset = train(use_physics=False)\n",
    "\n",
    "# --- (Optional) Run Physics-Informed Training ---\n",
    "# Uncomment the line below to train with Physics Loss enabled\n",
    "model_pinn, dataset = train(use_physics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Load a validation batch and compute metrics\n",
    "def sanity_check(model, dataset, device, K):\n",
    "    \"\"\"\n",
    "    Run inference on a single batch and visualize results with metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Get a small subset\n",
    "    val_loader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "    x, y = next(iter(val_loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(pred, y, K)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"SANITY CHECK METRICS\")\n",
    "    print(\"=\" * 60)\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:20s}: {v:.6f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Visualize first sample\n",
    "    visualize_field_comparison(x, pred, y, idx=0, save_path=f\"{OUTPUT_DIR}/sanity_check.png\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run sanity check after training\n",
    "# Uncomment after training completes:\n",
    "# sanity_metrics = sanity_check(model, dataset, device, dataset.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check & Visualization\n",
    "Quick validation of a single batch to check improvements."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8927398,
     "sourceId": 14013478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

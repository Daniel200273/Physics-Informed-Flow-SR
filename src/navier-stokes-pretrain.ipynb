{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14176776,"sourceType":"datasetVersion","datasetId":9036974}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports and Setup\nUpdated with NOISE_STD, VGG_WEIGHT, and library imports. Checks for GPU availability","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm.notebook import tqdm  # Use notebook version of tqdm\nimport matplotlib.pyplot as plt\n\n# Set seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# --- Configuration ---\nBATCH_SIZE = 4          # Keep small (4) to prevent OOM on Kaggle P100/T4\nLEARNING_RATE_G = 1e-4\nLEARNING_RATE_D = 1e-4\nEPOCHS = 100            # INCREASED: Train longer for better convergence\nPRETRAIN_EPOCHS = 20    # INCREASED: Longer warmup (MSE only) for stability\n\n# Loss Weights\nMSE_WEIGHT = 1.0        # Content Loss\nPHYSICS_WEIGHT = 0.2    # INCREASED: Stronger physics constraint (was 0.1)\nADVERSARIAL_WEIGHT = 0.001 # GAN Loss (Keep small!)\n\nOUTPUT_DIR = \"/kaggle/working\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üöÄ Device: {DEVICE}\")\n\n# --- Dataset Discovery ---\nsearch_path = \"/kaggle/input/**/*.pt\"\npt_files = glob.glob(search_path, recursive=True)\n\nif not pt_files:\n    print(\"‚ö†Ô∏è  No .pt file found automatically. Please check your path.\")\n    DATA_FILE = \"dataset/native_64.pt\" \nelse:\n    DATA_FILE = pt_files[0]\n    print(f\"üìÇ Dataset found at: {DATA_FILE}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T09:57:09.703976Z","iopub.execute_input":"2025-12-15T09:57:09.704317Z","iopub.status.idle":"2025-12-15T09:57:09.717763Z","shell.execute_reply.started":"2025-12-15T09:57:09.704292Z","shell.execute_reply":"2025-12-15T09:57:09.717085Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Class \nAdded ```noise_std``` parameter for Sim-to-Real gap augmentation.","metadata":{}},{"cell_type":"code","source":"class FluidLoader(Dataset):\n    def __init__(self, pt_file):\n        print(f\"‚è≥ Loading data from {pt_file}...\")\n        try:\n            data = torch.load(pt_file, map_location='cpu', mmap=True)\n        except:\n            print(\"‚ö†Ô∏è mmap failed. Loading entire dataset to RAM.\")\n            data = torch.load(pt_file, map_location='cpu')\n            \n        self.inputs = data['inputs']\n        self.targets = data['targets']\n        \n        self.K_vel = float(data.get('K_vel', 1.0))\n        self.K_pres = float(data.get('K_pres', 1.0))\n        self.K_smoke = float(data.get('K_smoke', 1.0))\n            \n        print(f\"‚úÖ Loaded {len(self.inputs)} samples.\")\n        print(f\"   Normalization: v={self.K_vel}, p={self.K_pres}, s={self.K_smoke}\")\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        lr = self.inputs[idx].float()\n        hr = self.targets[idx].float()\n        \n        if lr.shape[-1] == 256:\n            lr = F.interpolate(lr.unsqueeze(0), size=(64, 64), mode='bilinear', align_corners=False).squeeze(0)\n            \n        return lr, hr","metadata":{"execution":{"iopub.status.busy":"2025-12-15T09:57:09.719111Z","iopub.execute_input":"2025-12-15T09:57:09.719411Z","iopub.status.idle":"2025-12-15T09:57:09.733125Z","shell.execute_reply.started":"2025-12-15T09:57:09.719394Z","shell.execute_reply":"2025-12-15T09:57:09.732578Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Architecture (ResUNet)","metadata":{}},{"cell_type":"code","source":"# --- Generator (SRResNet) ---\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.prelu = nn.PReLU()\n        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(channels)\n\n    def forward(self, x):\n        residual = x\n        out = self.prelu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        return out + residual\n\nclass UpsampleBlock(nn.Module):\n    def __init__(self, in_channels, scale_factor):\n        super(UpsampleBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, in_channels * (scale_factor ** 2), kernel_size=3, padding=1)\n        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n        self.prelu = nn.PReLU()\n\n    def forward(self, x):\n        return self.prelu(self.pixel_shuffle(self.conv(x)))\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=4, out_channels=4, hidden_channels=64, num_res_blocks=16):\n        super(Generator, self).__init__()\n        \n        # Initial Feature Extraction\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, hidden_channels, kernel_size=9, padding=4),\n            nn.PReLU()\n        )\n\n        # Residual Trunk\n        res_blocks = []\n        for _ in range(num_res_blocks):\n            res_blocks.append(ResidualBlock(hidden_channels))\n        self.res_blocks = nn.Sequential(*res_blocks)\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_channels)\n        )\n\n        # Upsampling (two 2x blocks for 4x total)\n        self.upsample = nn.Sequential(\n            UpsampleBlock(hidden_channels, 2),\n            UpsampleBlock(hidden_channels, 2)\n        )\n\n        # Final Reconstruction\n        self.final_conv = nn.Conv2d(hidden_channels, out_channels, kernel_size=9, padding=4)\n\n    def forward(self, x):\n        out1 = self.conv1(x)\n        out = self.res_blocks(out1)\n        out = self.conv2(out)\n        out = out + out1 # Global Skip Connection\n        out = self.upsample(out)\n        out = self.final_conv(out)\n        return out\n\n# --- Discriminator (VGG-Style) ---\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=4, hidden_channels=64):\n        super(Discriminator, self).__init__()\n        \n        def conv_block(in_c, out_c, stride=1, bn=True):\n            layers = [nn.Conv2d(in_c, out_c, 3, stride, 1, bias=False)]\n            if bn: layers.append(nn.BatchNorm2d(out_c))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.features = nn.Sequential(\n            *conv_block(in_channels, hidden_channels, stride=1, bn=False),\n            *conv_block(hidden_channels, hidden_channels, stride=2, bn=True),\n            *conv_block(hidden_channels, hidden_channels*2, stride=1, bn=True),\n            *conv_block(hidden_channels*2, hidden_channels*2, stride=2, bn=True),\n            *conv_block(hidden_channels*2, hidden_channels*4, stride=1, bn=True),\n            *conv_block(hidden_channels*4, hidden_channels*4, stride=2, bn=True),\n            *conv_block(hidden_channels*4, hidden_channels*8, stride=1, bn=True),\n            *conv_block(hidden_channels*8, hidden_channels*8, stride=2, bn=True),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(hidden_channels*8, 1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, 1)\n            # No Sigmoid here because we use BCEWithLogitsLoss\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        return self.classifier(x)","metadata":{"execution":{"iopub.status.busy":"2025-12-15T09:57:09.733923Z","iopub.execute_input":"2025-12-15T09:57:09.734250Z","iopub.status.idle":"2025-12-15T09:57:09.755082Z","shell.execute_reply.started":"2025-12-15T09:57:09.734224Z","shell.execute_reply":"2025-12-15T09:57:09.754476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Functions ( VGG, Physics Informed)","metadata":{}},{"cell_type":"code","source":"class PressurePoissonLoss(nn.Module):\n    def __init__(self):\n        super(PressurePoissonLoss, self).__init__()\n        self.register_buffer('laplacian', torch.tensor([[[[0, 1, 0], [1, -4, 1], [0, 1, 0]]]], dtype=torch.float32))\n        self.register_buffer('k_x', torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]], dtype=torch.float32) / 8.0)\n        self.register_buffer('k_y', torch.tensor([[[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]]], dtype=torch.float32) / 8.0)\n\n    def get_grads(self, f):\n        return F.conv2d(f, self.k_x, padding=1), F.conv2d(f, self.k_y, padding=1)\n\n    def get_laplacian(self, f):\n        return F.conv2d(f, self.laplacian, padding=1)\n\n    def get_divergence(self, fx, fy):\n        dfx_dx, _ = self.get_grads(fx)\n        _, dfy_dy = self.get_grads(fy)\n        return dfx_dx + dfy_dy\n\n    def forward(self, pred, K_vel, K_pres, K_smoke):\n        # Unpack and Un-normalize\n        u = pred[:, 0:1, :, :] * K_vel\n        v = pred[:, 1:2, :, :] * K_vel\n        p = pred[:, 2:3, :, :] * K_pres\n        s = pred[:, 3:4, :, :] * K_smoke\n\n        lhs = self.get_laplacian(p)\n\n        du_dx, du_dy = self.get_grads(u)\n        dv_dx, dv_dy = self.get_grads(v)\n        conv_u = u * du_dx + v * du_dy \n        conv_v = u * dv_dx + v * dv_dy \n        div_convection = self.get_divergence(conv_u, conv_v)\n\n        force_y = s * 0.3\n        div_force = self.get_divergence(torch.zeros_like(s), force_y)\n\n        rhs = -div_convection + div_force\n        return F.mse_loss(lhs, rhs)","metadata":{"execution":{"iopub.status.busy":"2025-12-15T09:57:09.755877Z","iopub.execute_input":"2025-12-15T09:57:09.756116Z","iopub.status.idle":"2025-12-15T09:57:09.771749Z","shell.execute_reply.started":"2025-12-15T09:57:09.756096Z","shell.execute_reply":"2025-12-15T09:57:09.771197Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"import gc\nfrom torch.amp import autocast, GradScaler\n\ndef train_srgan():\n    # --- 1. MEMORY CLEANUP ---\n    # Clear old variables and GPU cache to prevent OOM\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # --- 2. Dataset Setup ---\n    dataset = FluidLoader(DATA_FILE)\n    train_sz = int(0.9 * len(dataset))\n    val_sz = len(dataset) - train_sz\n    train_ds, val_ds = random_split(dataset, [train_sz, val_sz], generator=torch.Generator().manual_seed(42))\n    \n    # Use global BATCH_SIZE\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n    # --- 3. Models Setup ---\n    netG = Generator(in_channels=4, out_channels=4).to(DEVICE)\n    netD = Discriminator(in_channels=4).to(DEVICE)\n\n    optimizerG = optim.Adam(netG.parameters(), lr=LEARNING_RATE_G)\n    optimizerD = optim.Adam(netD.parameters(), lr=LEARNING_RATE_D)\n\n    # --- 4. Losses & AMP Scaler ---\n    mse_fn = nn.MSELoss()\n    gan_fn = nn.BCEWithLogitsLoss()\n    phys_fn = PressurePoissonLoss().to(DEVICE)\n    scaler = GradScaler('cuda') # For Mixed Precision\n    \n    K_vel, K_pres, K_smoke = dataset.K_vel, dataset.K_pres, dataset.K_smoke\n\n    print(f\"\\nüöÄ Starting SRGAN Training (AMP Enabled, BS={BATCH_SIZE})...\")\n    print(f\"   Phase 1: Pre-training ({PRETRAIN_EPOCHS} epochs)\")\n    print(f\"   Phase 2: GAN Training ({EPOCHS - PRETRAIN_EPOCHS} epochs)\")\n\n    # --- Training Loop ---\n    for epoch in range(EPOCHS):\n        netG.train()\n        netD.train()\n        \n        is_pretraining = epoch < PRETRAIN_EPOCHS\n        phase_name = \"PRE-TRAIN\" if is_pretraining else \"GAN-TRAIN\"\n        \n        loss_g_accum = 0.0\n        loss_d_accum = 0.0\n        \n        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [{phase_name}]\", leave=False)\n        \n        for lr_img, hr_img in loop:\n            lr_img = lr_img.to(DEVICE)\n            hr_img = hr_img.to(DEVICE)\n            \n            # --- 1. Train Generator ---\n            optimizerG.zero_grad()\n            \n            with autocast('cuda'): # Mixed Precision Context\n                sr_img = netG(lr_img)\n                \n                # Content Loss\n                loss_content = MSE_WEIGHT * mse_fn(sr_img, hr_img)\n                \n                # Physics Loss\n                loss_phys = PHYSICS_WEIGHT * phys_fn(sr_img, K_vel, K_pres, K_smoke)\n                \n                # Adversarial Loss (Phase 2)\n                loss_adv = 0.0\n                if not is_pretraining:\n                    pred_fake = netD(sr_img)\n                    loss_adv = ADVERSARIAL_WEIGHT * gan_fn(pred_fake, torch.ones_like(pred_fake))\n\n                loss_G = loss_content + loss_phys + loss_adv\n            \n            # Scaled Backward Pass\n            scaler.scale(loss_G).backward()\n            scaler.step(optimizerG)\n            scaler.update()\n            \n            loss_g_accum += loss_G.item()\n\n            # --- 2. Train Discriminator (Phase 2 Only) ---\n            loss_D = 0.0\n            if not is_pretraining:\n                optimizerD.zero_grad()\n                \n                with autocast('cuda'):\n                    # Real Loss\n                    pred_real = netD(hr_img)\n                    loss_d_real = gan_fn(pred_real, torch.ones_like(pred_real))\n                    \n                    # Fake Loss (Detach to freeze G)\n                    pred_fake = netD(sr_img.detach())\n                    loss_d_fake = gan_fn(pred_fake, torch.zeros_like(pred_fake))\n                    \n                    loss_D = (loss_d_real + loss_d_fake) / 2\n                \n                scaler.scale(loss_D).backward()\n                scaler.step(optimizerD)\n                scaler.update()\n                \n                loss_d_accum += loss_D.item()\n\n            loop.set_postfix(G=loss_G.item(), D=loss_D if not is_pretraining else 0.0)\n\n        # --- Validation ---\n        avg_g = loss_g_accum / len(train_loader)\n        avg_d = loss_d_accum / len(train_loader)\n        \n        netG.eval()\n        val_mse = 0.0\n        with torch.no_grad():\n            for lr, hr in val_loader:\n                lr, hr = lr.to(DEVICE), hr.to(DEVICE)\n                with autocast('cuda'):\n                    val_mse += mse_fn(netG(lr), hr).item()\n        val_mse /= len(val_loader)\n        \n        print(f\"Epoch {epoch+1} | {phase_name} | G_Loss: {avg_g:.5f} | D_Loss: {avg_d:.5f} | Val MSE: {val_mse:.6f}\")\n\n        # Save Checkpoints\n        os.makedirs(\"checkpoints\", exist_ok=True)\n        if (epoch+1) % 10 == 0 or epoch == EPOCHS-1:\n            torch.save(netG.state_dict(), f\"{OUTPUT_DIR}/SRGAN_Gen_epoch_{epoch+1}.pth\")\n            if not is_pretraining:\n                torch.save(netD.state_dict(), f\"{OUTPUT_DIR}/SRGAN_Disc_epoch_{epoch+1}.pth\")\n    \n    print(\"\\n‚úÖ Training Complete!\")\n    return netG","metadata":{"execution":{"iopub.status.busy":"2025-12-15T09:57:09.955469Z","iopub.execute_input":"2025-12-15T09:57:09.955997Z","iopub.status.idle":"2025-12-15T09:57:09.968689Z","shell.execute_reply.started":"2025-12-15T09:57:09.955975Z","shell.execute_reply":"2025-12-15T09:57:09.968063Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Execute\nRun this cell to start.","metadata":{}},{"cell_type":"code","source":"# Run the training pipeline\ngenerator_model = train_srgan()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}